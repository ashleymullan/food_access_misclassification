labs(x = expression(lambda),
y = "1-sided Bootstrapped p-value",
title = "First Generation") +
theme_minimal() +
scale_color_manual(name = "legend", values = leg.cols) +
theme(legend.position = "inside",
legend.position.inside = c(quantile(ls, 0.75), 0.2),
legend.title = element_blank(),
legend.key.width = unit(2, "cm"))
## Plot the average first generation p-values compared to the lambdas:
data.frame(ls = ls,
pvals = colMeans(pCE),
pval_comps = 1 - colMeans(pCE)) |>
ggplot(aes(x = ls, y = pvals)) +
geom_line(aes(color = "Intervention (x = 1)"), size = 1.5) +
geom_line(aes(y = pval_comps, color = "Control (x = 0)"),
size = 1.5) + #control
geom_hline(yintercept = 0.5, linetype = "dashed",
color = 'gray50', size = 1) +
ylim(c(0,1)) +
labs(x = expression(lambda),
y = "1-sided Bootstrapped p-value",
title = "First Generation") +
theme_minimal() +
scale_color_manual(name = "legend", values = leg.cols) +
theme(legend.position = "inside",
legend.position.inside = c(quantile(ls, 0.5), 0.2),
legend.title = element_blank(),
legend.key.width = unit(2, "cm"))
## Plot the average first generation p-values compared to the lambdas:
data.frame(ls = ls,
pvals = colMeans(pCE),
pval_comps = 1 - colMeans(pCE)) |>
ggplot(aes(x = ls, y = pvals)) +
geom_line(aes(color = "Intervention (x = 1)"), size = 1.5) +
geom_line(aes(y = pval_comps, color = "Control (x = 0)"),
size = 1.5) + #control
geom_hline(yintercept = 0.5, linetype = "dashed",
color = 'gray50', size = 1) +
ylim(c(0,1)) +
labs(x = expression(lambda),
y = "1-sided Bootstrapped p-value",
title = "First Generation") +
theme_minimal() +
scale_color_manual(name = "legend", values = leg.cols) +
theme(legend.position = "inside",
legend.position.inside = c(quantile(ls, 0.5), 0.2),
legend.title = element_blank(),
legend.key.width = unit(1, "cm"))
## Plot the average first generation p-values compared to the lambdas:
data.frame(ls = ls,
pvals = colMeans(pCE),
pval_comps = 1 - colMeans(pCE)) |>
ggplot(aes(x = ls, y = pvals)) +
geom_line(aes(color = "Intervention (x = 1)"), size = 1.5) +
geom_line(aes(y = pval_comps, color = "Control (x = 0)"),
size = 1.5) + #control
geom_hline(yintercept = 0.5, linetype = "dashed",
color = 'gray50', size = 1) +
ylim(c(0,1)) +
labs(x = expression(lambda),
y = "1-sided Bootstrapped p-value",
title = "First Generation") +
theme_minimal() +
scale_color_manual(name = "legend", values = leg.cols) +
theme(legend.position = "inside",
legend.position.inside = c(quantile(ls, 0.5), 0.2),
legend.title = element_blank(),
legend.key.width = unit(0.5, "cm"))
## Plot the average first generation p-values compared to the lambdas:
data.frame(ls = ls,
pvals = colMeans(pCE),
pval_comps = 1 - colMeans(pCE)) |>
ggplot(aes(x = ls, y = pvals)) +
geom_line(aes(color = "Intervention (x = 1)"), size = 1.5) +
geom_line(aes(y = pval_comps, color = "Control (x = 0)"),
size = 1.5) + #control
geom_hline(yintercept = 0.5, linetype = "dashed",
color = 'gray50', size = 1) +
ylim(c(0,1)) +
labs(x = expression(lambda),
y = "1-sided Bootstrapped p-value",
title = "First Generation") +
theme_minimal() +
scale_color_manual(name = "legend", values = leg.cols) +
theme(legend.position = "bottom",
#legend.position.inside = c(quantile(ls, 0.5), 0.2),
legend.title = element_blank(),
legend.key.width = unit(0.5, "cm"))
freqt(CUSTODY_START_DATE)
freqt(CUSTODY_START_DATE) |> head()
?freqt
View(freqt)
?table
freqt <- function(x) data |> pull({{x}}) |> table(useNA = "always")
View(freqt)
View(freqt)
data$CUSTODY_START_DATE
freqt(Client.s.Date.of.Birth)
data$Client.s.Date.of.Birth |> head()
data <- read.csv("/Volumes/Shared/Epstein BCC-COE/CANS1_CANS2_MEGA/CANS2/CANS2_MEGA_merged_data/CANS2-MEGA-20240811.csv")
slim_data  <- data |> select(
Custody.Date,
CUSTODY_START_DATE,
Client.s.Date.of.Birth,
Client.s.Gender, # (female or male)
race, #i(bwo)
Hispanic.Origin,
Adjudication,
Commitment.County,
Removal.County,
PERSON_ID, #id
ASSESSMENT_ID, #id
EVENT_ID #id
)
sda <- slim_data |> summarize()
sda
sda <- slim_data
sda <- slim_data |> summary()
sda
dim(slim_data)
sda <- slim_data
names(sda)
for(col in names(sda)){
freqt(col) |> head()
}
for(col in names(sda)){
print(freqt(col) |> head())
}
for(col in names(sda)){
print(paste(col,freqt(col) |> head()))
}
for(col in names(sda)){
print(col)
print(freqt(col) |> head())
}
type(data$Client.s.Gender)
str(data$Client.s.Gender)
sda <- slim_data |>
mutate(dob = as.Date(Client.s.Date.of.Birth),
csd = as.Date(CUSTODY_START_DATE),
gender = as.factor(Client.s.Gender),
race = as.factor(race),
hispanic = as.factor(Hispanic.Origin),
adj = as.factor(Adjudication))
#fix age
sda |>
mutate(age = csd - dob) |> head()
#fix age
sda |>
mutate(age = csd - dob) |> pull(age) |> head()
#fix age
sda |>
mutate(age = floor((csd - dob)/365.25)) |> pull(age) |> head()
#fix age
sda |>
mutate(age = floor((csd - dob)/365.25)) |> head()
#fix age
sda <- sda |>
mutate(age = floor((csd - dob)/365.25))
sda |> head()
str(sda$age)
sda[1,"age"]
sda |>
mutate(age = floor(as.integer(csd - dob)/365.25)) |> pull(age) |> head()
#fix age
sda <- sda |>
mutate(age = floor(as.integer(csd - dob)/365.25))
sda
sda |> head()
sda |> pull(age) |> table(useNA = "always")
#count individual person/assessment combos
nrow(unique(sda[,c('PERSON_ID','ASSESSMENT_ID')]))
dummy <- data.frame(pers = c(1,3,2,5,2),)
dummy <- data.frame(pers = c(1,3,2,5,2),
aid = c(1,1,2,1,1))
dummy
#count to check matching number of assessment id and custody start date
nrow(unique(sda[,c('csd', 'ASSESSMENT_ID')]))
nrow(unique(sda[,c("ASSESSMENT_ID")]))
nrow(unique(sda[,"ASSESSMENT_ID"]))
sda[,'ASSESSMENT_ID'] |> head()
nrow(unique(sda$ASSESSMENT_ID))
length(unique(sda$ASSESSMENT_ID))
length(unique(sda$CUSTODY_START_DATE))
sda |> group_by(ASSESSMENT_ID) |> summarize(n = n()) |> arrange(desc(n))
sda |> group_by(ASSESSMENT_ID) |> summarize(n = n()) |> arrange(desc(n)) |> head()
sda |> group_by(csd) |> summarize(n = n()) |> arrange(desc(n)) |> head()
sda[!duplicated(sda), ] |> nrow()
sda |> nrow()
slim_data |> nrow()
data |> nrow()
data[!duplicated(data), ] |> nrow()
219328 - 169477
49851/219328
length(unique(sda$CUSTODY_START_DATE))
dummy |> arrange(person)
dummy |> arrange(pers)
dummy <- data.frame(pers = c(1,3,2,5,2),
aid = c(1,1,2,1,1),
abc = c(TRUE, FALSE, TRUE, FALSE, FALSE))
dummy |> arrange(pers)
dummy <- data.frame(pers = c(1,3,2,5,2,2),
aid = c(1,1,2,1,1,3),
abc = c(TRUE, FALSE, TRUE, FALSE, FALSE, TRUE))
dummy |> arrange(pers)
dummy |> arrange(pers,aid)
sda |> group_by(ASSESSMENT_ID) |> summarize(n = n()) |> arrange(desc(n)) |> head()
sda |> group_by(csd) |> summarize(n = n()) |> arrange(desc(n)) |> head()
sda |> group_by(csd) |> summarize(n = n()) |> arrange(desc(n)) |> head() #up to 189 per date
#sort by custody
sda <- sda |> arrange(csd)
sda |> head()
sda$PERSON_ID |> head()
temp <- sda |> filter(PERSON_ID == 1065998)
temp
names(sda)
sda |>
dplyr::select(age, gender, race, hispanic, adj, commitment.county) |>
gtsummary::tbl_summary(
missing_text = "(Missing)",
#by = grouping_var,
statistic = list(
all_continuous() ~ "{mean} ({sd})",
all_categorical() ~ "{n} / {N} ({p}%)"
)#,
#digits = c(var1, var2) ~ 2,
#label = vent.los.tot.s ~ "Days on Mechanical Ventilation"
) |>
add_n(statistic = "{N_miss}", col_label = "Overall Missing", last = TRUE)  |>
modify_caption("**Table 1. Draft**") |>
#modify_spanning_header(all_stat_cols() ~ "**Spanning Header**") |>
bold_labels() #I really like this package: https://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html in the past I was using table1()
library(gtsummary)
sda |>
dplyr::select(age, gender, race, hispanic, adj, commitment.county) |>
gtsummary::tbl_summary(
missing_text = "(Missing)",
#by = grouping_var,
statistic = list(
all_continuous() ~ "{mean} ({sd})",
all_categorical() ~ "{n} / {N} ({p}%)"
)#,
#digits = c(var1, var2) ~ 2,
#label = vent.los.tot.s ~ "Days on Mechanical Ventilation"
) |>
add_n(statistic = "{N_miss}", col_label = "Overall Missing", last = TRUE)  |>
modify_caption("**Table 1. Draft**") |>
#modify_spanning_header(all_stat_cols() ~ "**Spanning Header**") |>
bold_labels() #I really like this package: https://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html in the past I was using table1()
sda |>
dplyr::select(age, gender, race, hispanic, adj, Commitment.County) |>
gtsummary::tbl_summary(
missing_text = "(Missing)",
#by = grouping_var,
statistic = list(
all_continuous() ~ "{mean} ({sd})",
all_categorical() ~ "{n} / {N} ({p}%)"
)#,
#digits = c(var1, var2) ~ 2,
#label = vent.los.tot.s ~ "Days on Mechanical Ventilation"
) |>
add_n(statistic = "{N_miss}", col_label = "Overall Missing", last = TRUE)  |>
modify_caption("**Table 1. Draft**") |>
#modify_spanning_header(all_stat_cols() ~ "**Spanning Header**") |>
bold_labels() #I really like this package: https://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html in the past I was using table1()
sda |>
dplyr::select(age, gender, race, hispanic, adj, Commitment.County) |>
gtsummary::tbl_summary(
missing_text = "(Missing)",
#by = grouping_var,
statistic = list(
all_continuous() ~ "{mean} ({sd})",
all_categorical() ~ "{n} / {N} ({p}%)"
)#,
#digits = c(var1, var2) ~ 2,
#label = vent.los.tot.s ~ "Days on Mechanical Ventilation"
) |>
#add_n(statistic = "{N_miss}", col_label = "Overall Missing", last = TRUE)  |>
modify_caption("**Table 1. Draft**") |>
#modify_spanning_header(all_stat_cols() ~ "**Spanning Header**") |>
bold_labels() #I really like this package: https://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html in the past I was using table1()
set.seed(1001)
df <- data.frame(
yesno = sample(c('Y', 'N'), 10, replace = TRUE),
likert = sample(c('strong dis', 'dis', 'neut', 'agr', 'strong agr'), 10, replace = TRUE),
rep = rep(1:4, 1:4),
rand = rnorm(10)
)
df
apply(df, 2, is.numeric)
sapply(df, 2, is.numeric)
sapply(df, is.numeric)
sapply(df, is.numeric) #correctly assesses it
apply(df, 2, is.numeric) #wrong, even Cole doesn't know why
Filter(isTRUE, sapply(df, is.numeric))
names(sapply(df, is.numeric))
names(df)[sapply(df, is.numeric)]
table(df$likert)
table(df[,'likert'])[table(df[,'likert']) >= 3]
tab <- table(df[,'likert'])
tab[tab >= 3]
Filter(function(x) x >= 3, table(df$likert))
ge3 <- function(x) x >= 3
ge3 <- function(x) x >= 3; Filter(ge3, table(df$likert))
tbl <- function(dat, col) {
table(df[[col]])
}
tbl(df, likert)
tbl2 <- function(dat, col){
mycol <- substitute(col)
table(df[[mycol]])
}
tbl2(df, likert)
tbl3 <- function(dat, col){
table(df${{col}})
tbl3 <- function(dat, col){
table(df[[{{col}}]])
}
tbl3(df, likert)
qnorm(0.9)
qnorm(0.95)
qnorm(0.99)
qt(0.9, 10)
qt(0.95, 10)
qt(0.99, 10)
?qt
pnorm(1.64)
1 - pnorm(1.64)
qnorm(0.025)
devtools::install_github(repo = "baynezy/Html2Markdown")
################################################################################
# SETUP ########################################################################
################################################################################
## Load libraries
library(dplyr) ## to wrangle data
# Load data
## Dataset (1) Health outcomes from 2022 PLACES data
health = read.csv(file = "https://raw.githubusercontent.com/sarahlotspeich/food_access_imputation/main/piedmont-triad-data/disease_prevalences_2022.csv")
## Dataset (2) Proximity to health foods based on straight-line and map-based distances (census tracts)
food_access = read.csv(file = "https://raw.githubusercontent.com/sarahlotspeich/food_access_imputation/main/piedmont-triad-data/review_proximity_healthy_foods.csv") |>
right_join(health,
by = join_by(LocationID == TractFIPS))
## Define access indicators (at 1 mile buffer)
buffer = 1
food_access = food_access |>
mutate(binX_full = as.numeric(dist_closest_map <= buffer),
binXstar = as.numeric(dist_closest_straight <= buffer))
## Dataset (3) Rural urban
ruca = read.csv("https://raw.githubusercontent.com/sarahlotspeich/food_access_imputation/main/piedmont-triad-data/ruca2010revised.csv")
ruca_labels = c("Metropolitan", "Metropolitan", "Metropolitan",
"Micropolitan", "Micropolitan", "Micropolitan",
"Small town", "Small town", "Small town", "Rural")
food_access = food_access |>
dplyr::left_join(ruca, by = dplyr::join_by(LocationID == StateCountyTract)) |>
dplyr::mutate(PrimaryRUCA = factor(PrimaryRUCA,
labels = ruca_labels))
## Remove additional food access columns (not needed for primary analysis)
food_access = food_access |>
dplyr::select(LocationID, CountyName, ### keep neighborhood identifiers,
binX_full, binXstar, ### food access indicators,
LandArea, PopulationDensity, ### additional covariates,
POP, DIABETES) ### and outcome (with offset).
## Order by Location ID
food_access = food_access |>
arrange(LocationID)
## Define query indicators (= 1 if map-based measures are available, = 0 otherwise)
set.seed(918) ### make the sampling reproducible
n = 180
queried_subset = food_access |>
filter(binXstar == 1) |>
pull(LocationID) |>
sample(size = n, replace = FALSE)
### Create column for queried X from complete-case
food_access = food_access |>
mutate(binX_partial = ifelse(test = LocationID %in% queried_subset, #$LocationID,
yes = binX_full,
no = NA))
# Save data
food_access |>
mutate(CountyName = factor(x = CountyName,
levels = c("Alamance", "Caswell", "Davidson", "Davie",
"Forsyth", "Guilford", "Montgomery", "Randolph",
"Rockingham", "Stokes", "Surry", "Yadkin" ),
labels = LETTERS[1:12])) |>
dplyr::rename(O_POP = POP,
Y_DIABETES = DIABETES) |>
write.csv("food_access_misclassification/Analysis/piedmont_data.csv",
row.names = FALSE)
?write.csv
# Save data
food_access |>
mutate(CountyName = factor(x = CountyName,
levels = c("Alamance", "Caswell", "Davidson", "Davie",
"Forsyth", "Guilford", "Montgomery", "Randolph",
"Rockingham", "Stokes", "Surry", "Yadkin" ),
labels = LETTERS[1:12])) |>
dplyr::rename(O_POP = POP,
Y_DIABETES = DIABETES) |>
write.csv(file = "food_access_misclassification/Analysis/piedmont_data.csv",
row.names = FALSE)
getwd()
setwd("/Users/ashleymullan/Documents/Food-Access/food_access_misclassification/Analysis")
# Save data
food_access |>
mutate(CountyName = factor(x = CountyName,
levels = c("Alamance", "Caswell", "Davidson", "Davie",
"Forsyth", "Guilford", "Montgomery", "Randolph",
"Rockingham", "Stokes", "Surry", "Yadkin" ),
labels = LETTERS[1:12])) |>
dplyr::rename(O_POP = POP,
Y_DIABETES = DIABETES) |>
write.csv(file = "piedmont_data.csv",
row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("https://raw.githubusercontent.com/ashleymullan/food_access_misclassification/refs/heads/main/Analysis/piedmont_data_1.csv")
data <- read.csv("https://raw.githubusercontent.com/ashleymullan/food_access_misclassification/refs/heads/main/Analysis/piedmont_data.csv")
est = function(i, fit) {
round(exp(fit$coefficients[i]), 3)
}
lb = function(i, fit) {
se = sqrt(diag(vcov(fit)))[i]
round(exp(fit$coefficients[i] - 1.96 * se), 3)
}
ub = function(i, fit) {
se = sqrt(diag(vcov(fit)))[i]
round(exp(fit$coefficients[i] + 1.96 * se), 3)
}
ci = function(i, fit) {
se = sqrt(diag(vcov(fit)))[i]
paste(round(exp(fit$coefficients[i] + c(-1.96, 1.96) * se), 3), collapse = ", ")
}
data <- data |> mutate(LogLA = log(LandArea))
mod_diab_bn_gs_1 = summary(glm(formula = Y_DIABETES ~ binX_full + LogLA,
family = poisson(link = "log"),
offset = log(O_POP),
data = data_1))$coefficients
mod_diab_bn_gs = summary(glm(formula = Y_DIABETES ~ binX_full + LogLA,
family = poisson(link = "log"),
offset = log(O_POP),
data = data))$coefficients
mod_diab_bn_gs
mod_diab_bn_n = summary(glm(formula = Y_DIABETES ~ binXstar + LogLA,
family = poisson(link = "log"),
offset = log(O_POP),
data = data))$coefficients
#mles
mle_diab_bn = possum::mlePossum2(analysis_formula = Y_DIABETES ~ binX_partial + LogLA + offset(log(O_POP)),
error_formula = binX_partial ~ binXstar + LogLA,
beta_init = "Complete-data",
eta_init = "Complete-data",
data = data)$coefficients
mle_diab_bn
data |> head()
data <- data |> mutate(logpop = log(O_POP))
mle_diab_bn = possum::mlePossum2(analysis_formula = Y_DIABETES ~ binX_partial + LogLA + offset(logpop),
error_formula = binX_partial ~ binXstar + LogLA,
beta_init = "Complete-data",
eta_init = "Complete-data",
data = data)$coefficients
mle_diab_bn
temp <- read.csv("/Users/ashleymullan/Documents/Food-Access/food_access_misclassification/Simulations/One_Sided_Vary_PPV/one_sided_vary_ppv.csv")
temp |> head()
xtemp <- rnorm(50, mean = 4, sd = 1)
ytemp <- rnorm(50, mean = 4.2, sd = 1)
t.test(xtemp, ytemp, var.equal = TRUE, conf.level = 0.95)
temp_t_test <- t.test(xtemp, ytemp, var.equal = TRUE, conf.level = 0.95)
temp_t_test
temp_t_test$method
library(datasets)
boxplot(extra ~ group, data = sleep)
sleep
extra1 <- sleep$extra[sleep$group == '1']
extra2 <- sleep$extra[sleep$group == '2']
t.test(extra1, extra2, paired = TRUE, confidence = 0.95)
t.test(extra1, extra2, confidence = 0.95)
devtools::install_github("fstpackage/fst", ref = "develop")
#devtools::install_github("fstpackage/fst", ref = "develop")
library(readr)
fh <- reader::readr_example('challenge.csv')
?read_csv
tmp <- data.frame(a = 1:5, b = rnorm(5))
?load
tmp <- data.frame(a = 1:5, b = rnorm(5))
#saveRDS(tmp, file = 'file.rds')
save(tmp, file = 'file.Rdata')
load(file.Rdata)
getwd()
tmp
?load
environment()
list.files()
ls()
?ls
ls(sorted = FALSE)
readRDS_behavior <- function(filename) {
load(filename)
env_files <- ls()
name <- env_files[env_files != 'filename']
}
readRDS_behavior <- function(filename) {
load(filename)
env_files <- ls()
name <- env_files[env_files != 'filename']
get(name)
}
readRDS_behavior(tmp)
tmp <- data.frame(a = 1:5, b = rnorm(5))
#saveRDS(tmp, file = 'file.rds')
save(tmp, file = 'file.Rdata')
readRDS_behavior('file.Rdata')
?sample
